#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Sweep decision thresholds for the CHINESE K-fold ensemble predictions
and report the thresholds that give the best MCC and related metrics.

Assumes you have already run:
  python -m fine_tune_project.evaluation.evaluate_china_kfold_models

and that it produced:
  fine_tuned_models/china_kfold/china_kfold_ensemble_predictions.csv

This script:
- Loads the ensemble predictions CSV.
- Builds binary labels from the numeric label values using LABEL_THRESHOLD.
- Sweeps thresholds in [0, 1] (default step 0.01).
- Computes confusion matrix, ACC, Sensitivity, Specificity, MCC at each threshold.
- Computes AUC once (threshold-independent).
- Writes a CSV with all thresholds and metrics.
- Prints the threshold with best MCC (and shows its metrics and AUC).
"""

import os
import csv
import math

import numpy as np
from sklearn.metrics import roc_auc_score

from fine_tune_project.dsa_data_prep import THROMBUS_NO, THROMBUS_YES

# Path to ensemble predictions generated by evaluate_china_kfold_models.py
ENSEMBLE_PREDICTIONS_CSV = (
    "/media/nami/FastDataSpace/ThromboMap-Validation/original-train-repo/"
    "DeepLearningBasedDsaClassification-Validation/fine_tuned_models/china_kfold/"
    "china_kfold_ensemble_predictions.csv"
)

# Output CSV path for threshold sweep
THRESH_SWEEP_CSV = (
    "/media/nami/FastDataSpace/ThromboMap-Validation/original-train-repo/"
    "DeepLearningBasedDsaClassification-Validation/fine_tune_project/statistics/"
    "china_kfold_threshold_sweep.csv"
)

LABEL_THRESHOLD = (THROMBUS_NO + THROMBUS_YES) / 2.0


def compute_confusion_metrics(tp: int, tn: int, fp: int, fn: int):
    """Return (accuracy, sensitivity, specificity, mcc) from confusion counts."""
    total = tp + tn + fp + fn
    acc = (tp + tn) / total if total > 0 else 0.0
    sens = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0
    denom = math.sqrt(
        (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)
    ) if tp + fp > 0 and tp + fn > 0 and tn + fp > 0 and tn + fn > 0 else 0.0
    if denom == 0.0:
        mcc = 0.0
    else:
        mcc = ((tp * tn) - (fp * fn)) / denom
    return acc, sens, spec, mcc


def main():
    if not os.path.isfile(ENSEMBLE_PREDICTIONS_CSV):
        print(f"Ensemble predictions CSV not found: {ENSEMBLE_PREDICTIONS_CSV}")
        print("Run evaluate_china_kfold_models.py first.")
        return

    # Ensure output directory exists
    os.makedirs(os.path.dirname(THRESH_SWEEP_CSV), exist_ok=True)

    probs = []
    labels_numeric = []

    with open(ENSEMBLE_PREDICTIONS_CSV, newline="") as f:
        reader = csv.DictReader(f)
        for row in reader:
            try:
                prob = float(row["prob_combined"])
                label_val = float(row["label_value"])
            except (KeyError, ValueError):
                continue
            probs.append(prob)
            labels_numeric.append(label_val)

    if not probs:
        print("No valid rows found in ensemble predictions CSV.")
        return

    probs = np.array(probs)
    labels_numeric = np.array(labels_numeric)

    # Binary labels: 1 = thrombus, 0 = no-thrombus
    labels_bin = (labels_numeric > LABEL_THRESHOLD).astype(int)

    # Compute AUC once (threshold independent)
    auc = None
    if np.unique(labels_bin).size >= 2:
        try:
            auc = float(roc_auc_score(labels_bin, probs))
        except ValueError:
            auc = None

    thresholds = np.linspace(0.0, 1.0, 101)  # step 0.01
    rows = []
    best_mcc = -1.0
    best_row = None

    for thr in thresholds:
        preds = (probs > thr).astype(int)
        tp = int(np.sum((preds == 1) & (labels_bin == 1)))
        tn = int(np.sum((preds == 0) & (labels_bin == 0)))
        fp = int(np.sum((preds == 1) & (labels_bin == 0)))
        fn = int(np.sum((preds == 0) & (labels_bin == 1)))

        acc, sens, spec, mcc = compute_confusion_metrics(tp, tn, fp, fn)

        row = {
            "threshold": thr,
            "tp": tp,
            "tn": tn,
            "fp": fp,
            "fn": fn,
            "acc": acc,
            "sens": sens,
            "spec": spec,
            "mcc": mcc,
        }
        rows.append(row)

        if mcc > best_mcc:
            best_mcc = mcc
            best_row = row

    # Write sweep CSV
    with open(THRESH_SWEEP_CSV, "w", newline="") as f:
        writer = csv.DictWriter(
            f,
            fieldnames=["threshold", "tp", "tn", "fp", "fn", "acc", "sens", "spec", "mcc"],
        )
        writer.writeheader()
        writer.writerows(rows)

    print(f"Threshold sweep saved to: {THRESH_SWEEP_CSV}")

    if best_row is not None:
        print("\nBest threshold by MCC (using ensemble probabilities):")
        print(
            f"  threshold = {best_row['threshold']:.3f}\n"
            f"  MCC       = {best_row['mcc']:.4f}\n"
            f"  ACC       = {best_row['acc']:.4f}\n"
            f"  Sens      = {best_row['sens']:.4f}\n"
            f"  Spec      = {best_row['spec']:.4f}\n"
            f"  TP={best_row['tp']}, TN={best_row['tn']}, "
            f"FP={best_row['fp']}, FN={best_row['fn']}"
        )
    else:
        print("Could not determine best threshold (no valid MCCs).")

    if auc is not None:
        print(f"\nGlobal AUC (ensemble, independent of threshold) = {auc:.4f}")
    else:
        print("\nGlobal AUC could not be computed (only one class present).")


if __name__ == "__main__":
    main()





